{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Classification\n",
    "\n",
    "**Objective :** To classify different species of the Iris flower with the help of features provided.\n",
    "For this project we will be using the following UCI dataset- https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "It includes three iris species with 50 samples and some physical properties about each flower. \n",
    "\n",
    "\n",
    "Here are the features represented through columns :\n",
    "<br>\n",
    "\n",
    "**Input variables**\n",
    "<br>\n",
    "1 - Id\n",
    "<br>\n",
    "2 - sepal length in cm\n",
    "<br>\n",
    "3 - sepal width in cm\n",
    "<br>\n",
    "4 - petal length in cm\n",
    "<br>\n",
    "5 - petal width in cm\n",
    "<br>\n",
    "\n",
    "**Output variable**<br>\n",
    "6 - species:\n",
    "- Iris Setosa\n",
    "- Iris Versicolour\n",
    "- Iris Virginica\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps :\n",
    "1. Importing Libraries\n",
    "2. Exploring the Dataset\n",
    "3. Exploratory Data Analysis\n",
    "4. Data Preprocessing\n",
    "5. Model Building\n",
    "> * Logistic regression\n",
    "> * Decision tree\n",
    "> * KNN\n",
    "> * SVM\n",
    "> * Naive Bayes Classification\n",
    "> * Random forest\n",
    "> * XGBoost\n",
    "6. Performance Comparison\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "Import the necessary packages to process or plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data\n",
    "\n",
    "Use pandas to read iris.csv as a dataframe called iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check distribution of data**\n",
    "<br>\n",
    "Use head() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check information about the columns**\n",
    "<br>\n",
    "Use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's do some data visualization! Feel free to use whatever library you want. \n",
    "\n",
    "Note - Directions for a few plots are given below, we encourage you to explore further for more insights into the data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a countplot on the 'Species' column to find how the species are distributed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the distribution across species?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a correlation matrix to study the correlation between features!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we eliminate any of the features? (Are any of them correlated?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a scatter plot based on petal length and width.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which flower species seems to be the most separable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now plot one again based on sepal length and width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which flower species seems to be the most separable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a boxplot to find out the distribution of petal width across the 3 species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a boxplot to find out the distribution of petal length across the 3 species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a boxplot to find out the distribution of sepal width across the 3 species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a boxplot to find out the distribution of sepal length across the 3 species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the species column has entries in the form of species names. <br>\n",
    "\n",
    "**We will convert those species names to categorical values using label encoding.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's seperate the dataset as output variable (species name) and feature variabes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the 'Species' column to y\n",
    "#Drop the 'Species' and 'Id' column from the dataframe and set the remaining dataframe to x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets assign labels to our output variable using **LabelEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import LabelEncoder and create an instance named encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .fit_transform method to fit encoder to y and return encoded labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what Iris-setosa, Iris-versicolor and Iris-virginica are converted into respectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train_test_split\n",
    "\n",
    "\n",
    "#Split the data set into training data and testing data in a 7:3 ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building\n",
    "\n",
    "**Since it is a classification problem we will be using the following ML algorithms :**<br>\n",
    "Logistic regression<br>\n",
    "Decision tree<br>\n",
    "KNN<br>\n",
    "SVM<br>\n",
    "Naive Bayes Classification<br>\n",
    "Random forest<br>\n",
    "XGBoost<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/logitregression-161121215510/95/intro-to-logistic-regression-4-638.jpg?cb=1479765630\">\n",
    "\n",
    "Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import LogisticRegression\n",
    "\n",
    "\n",
    "#Create an instance of LogisticRegression() called lr_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result lr_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for LogisticRegression\n",
    "#Don't forget to import accuracy_score from sklearn.metrics!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "<img src=\"https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/04/Random-Forest-Introduction.jpg?resize=690%2C345\">\n",
    "\n",
    "\n",
    "Random Forest is considered to be a panacea of all data science problems. On a funny note, when you can’t think of any algorithm (irrespective of situation), use random forest!\n",
    "\n",
    "Random Forest is a versatile machine learning method capable of performing both regression and classification tasks. It also undertakes dimensional reduction methods, treats missing values, outlier values and other essential steps of data exploration, and does a fairly good job. It is a type of ensemble learning method, where a group of weak models combine to form a powerful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RandomForestClassifier\n",
    "\n",
    "\n",
    "#Create an instance of RandomForestClassifier() called rfc_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result rfc_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for RandomForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "<img src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/Knn_k1_z96jba.png\">\n",
    "\n",
    "K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#Create an instance of KNeighborsClassifier() with no. of neighbours = 3 called knn_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result knn_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*TudH6YvvH7-h5ZyF2dJV2w.jpeg\">\n",
    "\n",
    "“Support Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges. However, it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes very well.\n",
    "\n",
    "Support Vectors are simply the co-ordinates of individual observation. Support Vector Machine is a frontier which best segregates the two classes (hyper-plane/ line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SVC\n",
    "\n",
    "\n",
    "#Create an instance of SVC() called svm_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result svm_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification\n",
    "\n",
    "<img src=\"https://helloacm.com/wp-content/uploads/2016/03/Bayes_rule.png\">\n",
    "\n",
    "Naive Bayes is a simple, yet effective and commonly-used, machine learning classifier. It is a probabilistic classifier that makes classifications using the Maximum A Posteriori decision rule in a Bayesian setting. It can also be represented using a very simple Bayesian network. Naive Bayes classifiers have been especially popular for text classification, and are a traditional solution for problems such as spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import GaussianNB\n",
    "\n",
    "\n",
    "#Create an instance of GaussianNB() called nb_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result nb_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "<img src=\"https://annalyzin.files.wordpress.com/2016/07/decision-trees-titanic-tutorial.png\">\n",
    "\n",
    "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "#Create an instance of DecisionTreeClassifier() called dt_model with 3 nodes and fit it to the training data.\n",
    "\n",
    "\n",
    "#Create predictions from the test set and name the result dt_sgd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the accuracy score for DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "<img src=\"https://i.imgur.com/e7MIgXk.png\">\n",
    "\n",
    "The beauty of this powerful algorithm lies in its scalability, which drives fast learning through parallel and distributed computing and offers efficient memory usage.\n",
    "\n",
    "It’s no wonder then that CERN recognized it as the best approach to classify signals from the Large Hadron Collider. This particular challenge posed by CERN required a solution that would be scalable to process data being generated at the rate of 3 petabytes per year and effectively distinguish an extremely rare signal from background noises in a complex physical process. XGBoost emerged as the most useful, straightforward and robust solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import XGBClassifier\n",
    "\n",
    "\n",
    "#Create an instance of XGBClassifier() called xg_model and fit it to the training data.\n",
    "\n",
    "\n",
    "#Print out the model score applied on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison\n",
    "\n",
    "**You will now create an accuracy table to see all model performances in one glance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task will be to create 3 lists as mentioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list named 'scores'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list named 'models' with the following elements - LogisticRegression(), SVC(kernel='linear'), GaussianNB(), DecisionTreeClassifier(max_leaf_nodes=3), RandomForestClassifier(max_depth=3), KNeighborsClassifier(n_neighbors=3), xgb.XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list named 'classifiers' comprising of names of the algorithms in the list 'models' which you created above. \n",
    "#For e.g. SVC will be 'Support Vector Machine' and GuassianNB will be 'Naive Bayes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will use a for loop to implement the algorithms listed in 'models' above and append the accuracy score for each model to the list 'scores'.<br>\n",
    "Refer to the line - wise format of the loop which is given below\n",
    "\n",
    "**for i in models:**\n",
    "\n",
    "     Line 1 - set the value of a variable named 'current_model' equal to i\n",
    "     Line 2 - fit current_model to the training data\n",
    "     Line 3 - create predictions for the test set and store it in variable named 'current_prediction'\n",
    "     Line 4 - append the value accuracy_score(current_prediction,y_test) to the list 'scores'\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a dataframe named 'models_accuracy' with the data parameter set to 'scores' and index parameter set to 'classifiers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Print models_accuracy to see the dataframe you just created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "What insights did EDA give us about the dataset? <br>\n",
    "Which model gave the highest accuracy?<br>\n",
    "How did cross validation techniques and parameter tuning affect the results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
